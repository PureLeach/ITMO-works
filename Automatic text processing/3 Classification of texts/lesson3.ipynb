{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python394jvsc74a57bd077594395d1dbc7e532b1109311e8d416ccbba4c1ee0c9f1f05ad46b02508c705","display_name":"Python 3.9.4 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"colab":{"name":"3_Students.ipynb","provenance":[],"collapsed_sections":[]},"metadata":{"interpreter":{"hash":"77594395d1dbc7e532b1109311e8d416ccbba4c1ee0c9f1f05ad46b02508c705"}}},"cells":[{"cell_type":"code","metadata":{"id":"UnJwvQzbdnLb"},"source":["import pandas as pd\n","df = pd.read_csv('data.csv', encoding='latin-1')\n","df"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        v1                                                 v2 Unnamed: 2  \\\n","0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1      ham                      Ok lar... Joking wif u oni...        NaN   \n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3      ham  U dun say so early hor... U c already then say...        NaN   \n","4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","...    ...                                                ...        ...   \n","5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n","5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n","5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n","5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n","5571   ham                         Rofl. Its true to its name        NaN   \n","\n","     Unnamed: 3 Unnamed: 4  \n","0           NaN        NaN  \n","1           NaN        NaN  \n","2           NaN        NaN  \n","3           NaN        NaN  \n","4           NaN        NaN  \n","...         ...        ...  \n","5567        NaN        NaN  \n","5568        NaN        NaN  \n","5569        NaN        NaN  \n","5570        NaN        NaN  \n","5571        NaN        NaN  \n","\n","[5572 rows x 5 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will Ì_ b going to esplanade fr home?</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 5 columns</p>\n</div>"},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"xO59-HEadnLc","outputId":"470c6b7d-6e6f-4105-eab4-947debd213ef"},"source":["# Оставляем только интересующие нас колонки — тексты смс и метки:\n","df = df[['v1', 'v2']]\n","df = df.rename(columns = {'v1': 'label', 'v2': 'text'})\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  label                                               text\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"iveCG_bXdnLd"},"source":["# Удаляем дублирующиеся тексты:\n","df = df.drop_duplicates('text')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsKdfy6-dnLd"},"source":["# Заменяем метки на бинарные:\n","df['label'] = df['label'].map({'ham': 0, 'spam': 1})"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vQJK8LNdnLe"},"source":["### Предобработка текста (Задание 1)"]},{"source":["Нужно дополнить функцию для предобработки сообщений, которая делает с текстом следующее:\n","* приводит текст к нижнему регистру;\n","* удаляет стоп-слова;\n","* удаляет знаки препинания;\n","* нормализует текст при помощи стеммера Snowball.\n","\n","Предлагаем воспользоваться библиотекой nltk, чтобы не составлять список стоп-слов и не реализовывать алгоритм стемминга самостоятельно. Примеры использования стеммеров можно найти по ссылке (https://www.nltk.org/howto/stem.html)."],"cell_type":"markdown","metadata":{"id":"D8tefVdTdnLe"}},{"cell_type":"code","metadata":{"id":"yhU1BvAHdnLe"},"source":["# Для начала загружу стоп слова через терминал\n","# >> import nltk\n","# >> nltk.download(\"stopwords\")\n","import string\n","import nltk\n","from nltk import stem\n","from nltk.corpus import stopwords\n","import re\n","from nltk.stem.snowball import SnowballStemmer   \n","\n","stemmer = SnowballStemmer(\"english\")\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = text.lower()  # Приводим к нижнему регистру\n","    word_ws = text.split()  # Разбиваем текст на слова в списке\n","    # word_ws=[w.lower() for w in word if w.isalpha()]  \n","    filtered_sentence=[w for w in word_ws if w not in stop_words]  # Удаляем стоп-слова  \n","    normilize_sentence=[stemmer.stem(word) for word in filtered_sentence]  # Нормализуем текст при помощи стеммера Snowball\n","    text = (\" \").join(normilize_sentence)  # Вновь соединяем текст въедино\n","    \n","    return text\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["text = '''I'm gonna be home soon, and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.'''\n","x = preprocess(text)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QM-Lrt6ddnLe"},"source":["Проверка, что функция работает верно"]},{"cell_type":"code","metadata":{"id":"RSuPqUb2dnLe"},"source":["assert preprocess(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\") == \"im gonna home soon dont want talk stuff anymor tonight k ive cri enough today\"\n","assert preprocess(\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\") == \"go jurong point crazi avail bugi n great world la e buffet cine got amor wat\""],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"84H8mOmpdnLe"},"source":["Применяем получившуюся функцию к текстам:"]},{"cell_type":"code","metadata":{"id":"NtM4626ednLe","tags":[]},"source":["df['text'] = df['text'].apply(preprocess)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gRyqtqUtdnLe"},"source":["### Разделение данных на обучающую и тестовую выборки (Задание 2)"]},{"cell_type":"code","metadata":{"id":"nt7Z5NCMdnLe"},"source":["y = df['label'].values"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6r4PJBctdnLe"},"source":["Теперь нужно разделить данные на тестовую (test) и обучающую (train) выборку. В библиотеке scikit-learn для этого есть готовые инструменты."]},{"cell_type":"code","metadata":{"id":"r1c9ARWIdnLe"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.35, random_state=30)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KOV7Ub4ldnLe"},"source":["### Обучение классификатора (Задание 3)"]},{"source":["Переходим к обучению классификатора.\n","\n","Сначала извлекаем признаки из текстов. Рекомендуем попробовать разные способы и посмотреть, как это влияет на результат (подробнее о различных способах представления текстов можно прочитать по ссылке https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n","\n","Затем обучаем классификатор. Мы используем SVM, но можно поэкспериментировать с различными алгоритмами."],"cell_type":"markdown","metadata":{"id":"enAzNefqdnLe"}},{"cell_type":"code","metadata":{"id":"QtfcmJ7NdnLe"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","\n","# Извлекаем признаки из текстов\n","vectorizer = TfidfVectorizer(decode_error='ignore')\n","X_train = vectorizer.fit_transform(X_train)\n","X_test = vectorizer.transform(X_test)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIQQo8j3dnLe"},"source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import classification_report\n","\n","# Обучаем модель SVM\n","model = LinearSVC(random_state = 30, C = 1.1)\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)"],"execution_count":12,"outputs":[]},{"source":["Для самопроверки. Если вы верно дополнили функцию ```preprocess```, то должны получиться следующие результаты оценки модели."],"cell_type":"markdown","metadata":{"id":"sn9kvQaZdnLe"}},{"cell_type":"code","metadata":{"id":"zGxDEYnjdnLe","outputId":"104a68f1-cf8a-421e-cc3f-2b63b99c2520"},"source":["print(classification_report(y_test, predictions, digits=3))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n\n           0      0.980     0.996     0.988      1568\n           1      0.972     0.868     0.917       242\n\n    accuracy                          0.979      1810\n   macro avg      0.976     0.932     0.953      1810\nweighted avg      0.979     0.979     0.978      1810\n\n"]}]},{"cell_type":"markdown","metadata":{"id":"1nffLu6UdnLf"},"source":["Выполним предсказание для конкретного текста"]},{"cell_type":"code","metadata":{"id":"prWswDzudnLf"},"source":["txt = \"Excellent collection of articles and speeches.\"\n","txt = preprocess(txt)\n","txt = vectorizer.transform([txt])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"brfpnzR7dnLf","outputId":"5220b6fe-a3a6-45f4-e726-b3f813ac7751"},"source":["# 0 соответствует ham, 1 -- spam\n","model.predict(txt)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0], dtype=int64)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}